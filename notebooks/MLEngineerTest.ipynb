{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import URL\n",
    "import sqlalchemy.dialects.sqlite\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date,timedelta\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "from random import random\n",
    "import plotly.graph_objects as go\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>to_user_distance</th>\n",
       "      <th>to_user_elevation</th>\n",
       "      <th>total_earning</th>\n",
       "      <th>created_at</th>\n",
       "      <th>taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14364873</td>\n",
       "      <td>30000009</td>\n",
       "      <td>2.478101</td>\n",
       "      <td>-72.719360</td>\n",
       "      <td>4200</td>\n",
       "      <td>2017-09-07T20:02:17Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14370123</td>\n",
       "      <td>30000058</td>\n",
       "      <td>0.451711</td>\n",
       "      <td>37.754761</td>\n",
       "      <td>4200</td>\n",
       "      <td>2017-09-07T20:13:16Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14368534</td>\n",
       "      <td>900003684</td>\n",
       "      <td>2.026072</td>\n",
       "      <td>207.191162</td>\n",
       "      <td>4000</td>\n",
       "      <td>2017-09-07T20:07:23Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14370258</td>\n",
       "      <td>900014452</td>\n",
       "      <td>2.671432</td>\n",
       "      <td>1.722656</td>\n",
       "      <td>4400</td>\n",
       "      <td>2017-09-07T20:15:19Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14369923</td>\n",
       "      <td>900014085</td>\n",
       "      <td>0.965496</td>\n",
       "      <td>117.429199</td>\n",
       "      <td>3450</td>\n",
       "      <td>2017-09-07T20:12:14Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id   store_id  to_user_distance  to_user_elevation  total_earning  \\\n",
       "0  14364873   30000009          2.478101         -72.719360           4200   \n",
       "1  14370123   30000058          0.451711          37.754761           4200   \n",
       "2  14368534  900003684          2.026072         207.191162           4000   \n",
       "3  14370258  900014452          2.671432           1.722656           4400   \n",
       "4  14369923  900014085          0.965496         117.429199           3450   \n",
       "\n",
       "             created_at  taken  \n",
       "0  2017-09-07T20:02:17Z      0  \n",
       "1  2017-09-07T20:13:16Z      0  \n",
       "2  2017-09-07T20:07:23Z      0  \n",
       "3  2017-09-07T20:15:19Z      1  \n",
       "4  2017-09-07T20:12:14Z      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Usuario/Downloads/orders.csv', sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "store_id             0\n",
       "to_user_distance     0\n",
       "to_user_elevation    0\n",
       "total_earning        0\n",
       "created_at           0\n",
       "taken                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dates'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['dates'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "store_id             0\n",
       "to_user_distance     0\n",
       "to_user_elevation    0\n",
       "total_earning        0\n",
       "created_at           0\n",
       "taken                0\n",
       "dates                0\n",
       "weekday              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df[['to_user_distance', 'to_user_elevation', 'total_earning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(numerical_features.corr())\n",
    "plt.xticks(range(len(numerical_features.columns)), numerical_features.columns,rotation=90)\n",
    "plt.yticks(range(len(numerical_features.columns)), numerical_features.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "    y=df['to_user_distance'],\n",
    "    name=\"Suspected Outliers\",\n",
    "    boxpoints='suspectedoutliers', # only suspected outliers\n",
    "    marker=dict(\n",
    "        color='rgb(8,81,156)',\n",
    "        outliercolor='rgba(219, 64, 82, 0.6)',\n",
    "        line=dict(\n",
    "            outliercolor='rgba(219, 64, 82, 0.6)',\n",
    "            outlierwidth=2)),\n",
    "    line_color='rgb(8,81,156)'\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\"Box Plot Styling Outliers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['to_user_distance'].hist(bins=8) \n",
    "plt.xlabel(\"Duración en minutos\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "    y=df['to_user_elevation'],\n",
    "    name=\"Suspected Outliers\",\n",
    "    boxpoints='suspectedoutliers', # only suspected outliers\n",
    "    marker=dict(\n",
    "        color='rgb(8,81,156)',\n",
    "        outliercolor='rgba(219, 64, 82, 0.6)',\n",
    "        line=dict(\n",
    "            outliercolor='rgba(219, 64, 82, 0.6)',\n",
    "            outlierwidth=2)),\n",
    "    line_color='rgb(8,81,156)'\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\"Box Plot Styling Outliers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['to_user_elevation'].hist(bins=8) \n",
    "plt.xlabel(\"Duración en minutos\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "    y=df['total_earning'],\n",
    "    name=\"Suspected Outliers\",\n",
    "    boxpoints='suspectedoutliers', # only suspected outliers\n",
    "    marker=dict(\n",
    "        color='rgb(8,81,156)',\n",
    "        outliercolor='rgba(219, 64, 82, 0.6)',\n",
    "        line=dict(\n",
    "            outliercolor='rgba(219, 64, 82, 0.6)',\n",
    "            outlierwidth=2)),\n",
    "    line_color='rgb(8,81,156)'\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(title_text=\"Box Plot Styling Outliers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_earning'].hist(bins=8) \n",
    "plt.xlabel(\"Duración en minutos\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['store_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['store_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiar outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "store_id             0\n",
       "to_user_distance     0\n",
       "to_user_elevation    0\n",
       "total_earning        0\n",
       "created_at           0\n",
       "taken                0\n",
       "dates                0\n",
       "weekday              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearn = data['total_earning'].quantile(.97)\n",
    "data = data.drop(data[data['total_earning']>pearn].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "store_id             0\n",
       "to_user_distance     0\n",
       "to_user_elevation    0\n",
       "total_earning        0\n",
       "created_at           0\n",
       "taken                0\n",
       "dates                0\n",
       "weekday              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(drop='first')\n",
    "x = onehotencoder.fit(data[['weekday']])\n",
    "x = x.transform(data[['weekday']]).toarray()\n",
    "clases = onehotencoder.get_feature_names()\n",
    "x = pd.DataFrame(x)\n",
    "x.columns = clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop = True)\n",
    "data = pd.concat([data, x], axis=1, sort=False)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_values(data, feature, y):\n",
    "    lst = []\n",
    "    for i in range(data[feature].nunique()):\n",
    "        val = list(data[feature].unique())[i]\n",
    "        lst.append({\n",
    "            'Value': val,\n",
    "            'All': data[data[feature] == val].count()[feature],\n",
    "            'Good': data[(data[feature] == val) & (data[y] == 1)].count()[feature],\n",
    "            'Bad': data[(data[feature] == val) & (data[y] == 0)].count()[feature]\n",
    "        })\n",
    "        \n",
    "    woe = pd.DataFrame(lst)\n",
    "    woe['Distr_Good'] = woe['Good'] / woe['Good'].sum()\n",
    "    woe['Distr_Bad'] = woe['Bad'] / woe['Bad'].sum()\n",
    "    woe['WoE'] = np.log(woe['Distr_Good'] / woe['Distr_Bad'])\n",
    "    woe = woe.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "    woe['IV'] = (woe['Distr_Good'] - woe['Distr_Bad']) * woe['WoE']\n",
    "    iv = woe['IV'].sum()\n",
    "    \n",
    "    woe = woe.sort_values(by='WoE')\n",
    "    \n",
    "    return woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:853: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "stores=woe_values(data,'store_id','taken')\n",
    "stores=stores.rename(columns ={\"Value\":\"store\", \"IV\":\"iv_store\"})\n",
    "stores = stores.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "sil = []\n",
    "kmax = 10\n",
    "\n",
    "# dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\n",
    "for k in range(2, kmax+1):\n",
    "    kmeans = KMeans(n_clusters = k).fit(np.array(stores['WoE']).reshape(-1,1))\n",
    "    \n",
    "    labels = kmeans.labels_\n",
    "    sil.append(silhouette_score(np.array(stores['WoE']).reshape(-1,1), labels, metric = 'euclidean'))\n",
    "\n",
    "plt.plot(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=0 )\n",
    "stores['clusters'] = kmeans.fit_predict(stores.WoE.values.reshape(-1,1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = stores[['store','clusters']]\n",
    "cl.set_index('store', drop=True, inplace=True)\n",
    "dic = cl.to_dict(orient=\"dict\")\n",
    "final = dic['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "store_id             0\n",
       "to_user_distance     0\n",
       "to_user_elevation    0\n",
       "total_earning        0\n",
       "created_at           0\n",
       "taken                0\n",
       "dates                0\n",
       "weekday              0\n",
       "store                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['store'] = data.store_id.map(final)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = [0, 1, 2, 3, 4, 5, 6]\n",
    "borrar = 0\n",
    "for x in todos:\n",
    "    if x in data['store'].unique():\n",
    "        pass\n",
    "    else:\n",
    "        data = data.append(pd.DataFrame({'store':[x]}), ignore_index=True, sort=True)\n",
    "        borrar = borrar + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(drop='first')\n",
    "x = onehotencoder.fit(data[['store']])\n",
    "x = x.transform(data[['store']]).toarray()\n",
    "clases = onehotencoder.get_feature_names()\n",
    "nombres=[]\n",
    "for n in clases:\n",
    "    nombres.append(str(n)[3])\n",
    "    \n",
    "x = pd.DataFrame(x)\n",
    "x.columns = nombres\n",
    "nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, x], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.tail(borrar).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = data.copy()\n",
    "dff = dff.drop(['created_at', 'dates', 'weekday', 'order_id', 'store_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 131459, 0: 11167})\n",
      "7.829568241414608\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "balan = collections.Counter(dff['taken'])\n",
    "porc = (balan[0]/(balan[0] + balan[1]))*100\n",
    "print(balan)\n",
    "print(porc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = data.loc[:, ('order_id', 'store', 'to_user_distance', 'to_user_elevation', 'total_earning','weekday', 'taken')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n = ['store', 'to_user_distance', 'to_user_elevation', 'total_earning', 'x0_Monday',\n",
    "       'x0_Saturday', 'x0_Sunday', 'x0_Thursday', 'x0_Tuesday', 'x0_Wednesday',\n",
    "       '1', '2', '3', '4', '5', '6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['store', 'to_user_distance', 'to_user_elevation', 'total_earning', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label ='taken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dn, \n",
    "                               test_size = 0.25,\n",
    "                               stratify = dn[label],\n",
    "                               random_state = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 98594, 0: 8375})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 98594, 0: 49297})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "over = RandomOverSampler(sampling_strategy=0.5)\n",
    "X_over, y_over = over.fit_resample(train[features], train[label])\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 61621, 0: 49297})\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(sampling_strategy=0.8)\n",
    "X_combined, y_combined = under.fit_resample(X_over, y_over)\n",
    "print(Counter(y_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline_imb([\n",
    "    ('class_balancer', SMOTE(random_state=1)),\n",
    "    ('classifier', RandomForestClassifier(random_state=1, n_estimators=600))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline_imb([\n",
    "    ('classifier', RandomForestClassifier(random_state=1, max_depth=11, n_estimators=500))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.fit(train[features], train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predict_val = model_pipeline.predict_proba(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(y_real, y_predicted):\n",
    "    tn = pd.np.sum(((y_real == y_predicted) & (y_real == 0)) * 1)\n",
    "    fp = pd.np.sum((y_real != y_predicted) & (y_predicted == 1) * 1)\n",
    "    return  tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_score(test_predictions, test, label, threshold):\n",
    "    predictions = test_predictions[:,1] >= threshold \n",
    "    \n",
    "    return {\n",
    "        'specificity': specificity(test[label], predictions),\n",
    "        'accuracy': accuracy_score(test[label], predictions),\n",
    "        'precision': precision_score(test[label], predictions),\n",
    "        'recall': recall_score(test[label],predictions),\n",
    "        'roc_auc': roc_auc_score(test[label], test_predictions[:,1]),\n",
    "        'false_positives': confusion_matrix(test[label], predictions).ravel()[1],\n",
    "        'true_positives': confusion_matrix(test[label], predictions).ravel()[3],\n",
    "        'false_negatives': confusion_matrix(test[label], predictions).ravel()[2],\n",
    "        'true_negatives': confusion_matrix(test[label], predictions).ravel()[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_score(rf_predict_val, test, label, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=1)\n",
    "param_grid = {'classifier__n_estimators':np.arange(200, 600, 100)}\n",
    "grid_search = GridSearchCV(model_pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           n_jobs=5,\n",
    "                           cv = 3,\n",
    "                           verbose=2)\n",
    "grid_search.fit(train[features], train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline_xg = Pipeline_imb([\n",
    "    ('classifier', XGBClassifier(subsample = 0.8,\n",
    "                        n_estimators = 300,\n",
    "                        min_child_weight = 5,\n",
    "                        max_depth = 5,\n",
    "                        learning_rate = 0.1,\n",
    "                        gamma = 0.5,\n",
    "                        colsample_bytree = 0.6,\n",
    "                        objective = 'binary:logistic'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['store', 'weekday']\n",
    "numerical_columns = ['to_user_distance', 'to_user_elevation', 'total_earning']\n",
    "numerical_transformer = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_transformer = Pipeline(steps = [('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "column_transformer = ColumnTransformer([('numerical_transformer', numerical_transformer, numerical_columns), ('categorical_transformer', categorical_transformer, categorical_columns)])\n",
    "preprocessor = Pipeline([('preprocessor', column_transformer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba=preprocessor.fit_transform(train[features], train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = preprocessor.transform(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline_xg.fit(prueba, train[label])\n",
    "rf_predict_val = model_pipeline_xg.predict_proba(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'specificity': 0.02363896848137536,\n",
       " 'accuracy': 0.9215862243037832,\n",
       " 'precision': 0.9232566650713663,\n",
       " 'recall': 0.9978700745473909,\n",
       " 'roc_auc': 0.7606980856826375,\n",
       " 'false_positives': 2726,\n",
       " 'true_positives': 32795,\n",
       " 'false_negatives': 70,\n",
       " 'true_negatives': 66}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_score(rf_predict_val, test, label, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'stores':final,\n",
    "        'preprocessing':preprocessor,\n",
    "        'model':model_pipeline_xg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelTest.pickle', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'classifier__n_estimators':np.arange(200, 600, 100),\n",
    "             'classifier__subsample':np.arange(0.5, 1, 0.2),\n",
    "             'classifier__min_child_weight':np.arange(5,10),\n",
    "             'classifier__max_depth':np.arange(5,10),\n",
    "             'classifier__learning_rate':np.arange(0.1,0.5),\n",
    "             'classifier__gamma':np.arange(0.5,1),\n",
    "             'classifier__colsample_bytree':np.arange(0.5,1)}\n",
    "grid_search = GridSearchCV(model_pipeline_xg,\n",
    "                           param_grid=param_grid,\n",
    "                           n_jobs=5,\n",
    "                           cv = 3,\n",
    "                           verbose=2)\n",
    "grid_search.fit(train[features], train[label])\n",
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
